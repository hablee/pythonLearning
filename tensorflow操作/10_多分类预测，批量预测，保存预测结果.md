    对剪刀、石头、布进行分类
# train_Function
```python
# 下载数据
import wget
url_train='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'
url_test='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'
file_train=wget.download(url_train)
file_test=wget.download(url_test)

# 解压数据
import zipfile
local_zip='./rps.zip'
zip_ref=zipfile.ZipFile(local_zip,'r')
zip_ref.extractall() # 解压
zip_ref.close()

local_zip='./rps-test-set.zip'
zip_ref=zipfile.ZipFile(local_zip,'r')
zip_ref.extractall() # 解压
zip_ref.close()

# 查看数据集信息
import os
rock_dir=os.path.join('./rps/rock')
paper_dir=os.path.join('./rps/paper')
scissors_dir=os.path.join('./rps/scissors')

print('total training rock images:',len(os.listdir(rock_dir)))
print('total training paper images:',len(os.listdir(paper_dir)))
print('total training scissors images:',len(os.listdir(scissors_dir)))

rock_files=os.listdir(rock_dir)
print(rock_files[:10])
paper_files=os.listdir(paper_dir)
print(paper_files[:10])
scissors_files=os.listdir(scissors_dir)
print(scissors_files[:10])

# 画图
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
pic_index=2
next_rock=[os.path.join(rock_dir,fname) for fname in rock_files[pic_index-2:pic_index]]
next_paper=[os.path.join(paper_dir,fname) for fname in paper_files[pic_index-2:pic_index]]
next_scissors=[os.path.join(scissors_dir,fname) for fname in scissors_files[pic_index-2:pic_index]]

for i,img_path in enumerate(next_rock+next_paper+next_scissors):
    img=mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

# 创建datagen
TRAINING_DIR='./rps'
training_datagen=ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',

)
VALIDATION_DIR='./rps-test-set'
validation_datagen=ImageDataGenerator(
    rescale=1./255,
)

# 创建datagenerator
train_generator=training_datagen.flow_from_directory(
    TRAINING_DIR,
    target_size=(150,150),
    class_mode='categorical',
)
validation_generator=validation_datagen.flow_from_directory(
    VALIDATION_DIR,
    target_size=(150,150),
    class_mode='categorical'
)

# 建立模型
model=tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(512,activation='relu'),
    tf.keras.layers.Dense(3,activation='softmax')
])

# 模型参数查看
model.summary()

# 模型编译
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])

# 模型拟合
history=model.fit(train_generator,epochs=5,validation_data=validation_generator)
# 模型保存
model.save('rps.h5')

# 查看acc曲线
import matplotlib.pyplot as plt
acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(len(acc))
plt.plot(epochs,acc,'r',label='Training accuracy')
plt.plot(epochs,val_acc,'b',label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.show()

```
# predict.py
    在当前项目下新建PREDICT文件夹，用来放要预测的图片
```python
import tensorflow as tf
import os

# 导入模型
model = tf.keras.models.load_model('rps.h5')

# 载入文件夹中的图片
PRIDICT_IMAGE_DIR='./PRIDICT'
files_name=os.listdir(PRIDICT_IMAGE_DIR)
next_image=[os.path.join(PRIDICT_IMAGE_DIR,fname) for fname in files_name]

# 新建保存的空csv
import pandas as pd
df=pd.DataFrame(columns=['文件名','第几类'])

# 预测图片
from keras_preprocessing import image
import numpy as np
i=0
for filename in next_image:
    image_path=filename
    img=image.load_img(image_path,target_size=(150,150))
    x=image.img_to_array(img)
    x=np.expand_dims(x,axis=0)
    print(x.shape)
    this_image=np.vstack([x])
    classes=model.predict(this_image,batch_size=10)
    # print(filename,classes[0])
    df.loc[i]=[filename,np.argmax(classes[0])+1] #第几类
    i+=1
# print(df)
# 保存结果
df.to_csv('predict_result.csv',index=False,sep=',',encoding='utf_8_sig')
```
