# 人和马的分类
    使用wget下载数据；自动调参
# code
```python
import wget

# url='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip'
# file_name = wget.filename_from_url(url)
# print(file_name)
#
# file_name = wget.download(url)
# print(file_name)

import os
import zipfile
# local_zip='horse-or-human.zip'
# zip_ref=zipfile.ZipFile(local_zip,'r')
# zip_ref.extractall('horse-or-human')
# zip_ref.close()

# local_zip='validation-horse-or-human.zip'
# zip_ref=zipfile.ZipFile(local_zip,'r')
# zip_ref.extractall('validation-horse-or-human')
# zip_ref.close()

# train_horse_dir=os.path.join('./horse-or-human/horses/')
# train_human_dir=os.path.join('./horse-or-human/humans/')


# train_horse_names=os.listdir(train_horse_dir) # 文件名
# # print(train_horse_names[:10])
# train_human_names=os.listdir(train_human_dir)
# print(train_human_names[:10])

# print('total training horse images:',len(os.listdir(train_horse_dir)))
# print('total training human images:',len(os.listdir(train_human_dir)))

# import matplotlib.pyplot as plt
# import matplotlib.image as mpimg
# nrows=4
# ncols=4
# pic_index=0
# fig=plt.gcf()
# fig.set_size_inches(ncols*4,nrows*4)
# pic_index+=8
# next_horse_pix=[os.path.join(train_horse_dir,fname)
#                 for fname in train_horse_names[pic_index-8:pic_index]]
# next_human_pix=[os.path.join(train_human_dir,fname)
#                 for fname in train_human_names[pic_index-8:pic_index]]
#
# for i, img_path in enumerate(next_horse_pix+next_human_pix):
#     sp= plt.subplot(nrows,ncols,i+1)
#     sp.axis('off')
#
#     img=mpimg.imread(img_path)
#     plt.imshow(img)
#
# plt.show()

import tensorflow as tf

# 建立模型
model=tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation='relu'),
    tf.keras.layers.Dense(1,activation='sigmoid')
])

model.summary()

# 编译模型
from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=RMSprop(lr=0.001),loss='binary_crossentropy',
              metrics=['acc'])

# ImageDataGenerator将文件夹名字联系图片标签
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(rescale=1/255)
train_generator=train_datagen.flow_from_directory(
    'horse-or-human',
    target_size=(150,150),
    batch_size=32,
    class_mode='binary'
)

# 训练模型
history=model.fit(train_generator,steps_per_epoch=8,
                  epochs=15,verbose=1)

# 运行模型
import numpy as np
from tensorflow.keras.preprocessing import image
img=image.load_img('hu.jpg',target_size=(150,150))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)
images=np.vstack([x])
classes=model.predict(images,batch_size=10)
print(classes[0])
if classes[0]>0.5:
    print('hu.jpg is a human')
else:
    print('hu.jpg is a horse')

# 将中间输出层可视化
# import random
# from tensorflow.keras.preprocessing.image import img_to_array,load_img
# import matplotlib.pyplot as plt
#
# successive_outputs=[layer.output for layer in model.layers[1:]]
# visualization_model=tf.keras.models.Model(inputs=model.input,outputs=successive_outputs)
# horse_img_files=[os.path.join(train_horse_dir,f) for f in train_horse_names]
# human_img_files=[os.path.join(train_human_dir,f) for f in train_human_names]
# img_path=random.choice(horse_img_files+human_img_files)
#
# img=load_img(img_path,target_size=(150,150))
# x=img_to_array(img)
# x=x.reshape((1,)+x.shape)
#
# x/=255
#
# successive_feature_maps=visualization_model.predict(x)
#
# layer_names=[layer.name for layer in model.layers]
#
# for layer_name,feature_map in zip(layer_names,successive_feature_maps):
#     if len(feature_map.shape)==4:
#         n_features=feature_map.shape[-1]
#         size=feature_map.shape[1]
#         display_grid=np.zeros((size,size*n_features))
#         for i in range(n_features):
#             x=feature_map[0,:,:,i]
#             x -= x.mean()
#             x /= x.std()
#             x *=64
#             x +=128
#             x = np.clip(x,0,255).astype('uint8')
#             display_grid[:,i*size:(i+1)*size] = x
#
#         scale=20./n_features
#         plt.figure(figsize=(scale*n_features,scale*n_features))
#         plt.title(layer_name)
#         plt.grid(False)
#         plt.imshow(display_grid,aspect='auto',cmap='viridis')
#         plt.show()

# 自动调参
# import os
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.optimizers import RMSprop
#
# train_datagen=ImageDataGenerator(rescale=1/255)
# validation_datagen=ImageDataGenerator(rescale=1/255)
# # 训练数据流
# train_generator=train_datagen.flow_from_directory('horse-or-human',
#                                                   target_size=(150,150),
#                                                   batch_size=32,
#                                                   class_mode='binary')
# validation_generator=validation_datagen.flow_from_directory('validation-horse-or-human',
#                                                           target_size=(150,150),
#                                                           batch_size=32,
#                                                           class_mode='binary')
# from kerastuner.tuners import Hyperband
# from kerastuner.engine.hyperparameters import HyperParameters
# import tensorflow as tf
#
# # 创建HyperParameters对象，在模型中插入Choice,Int等调参对象
# hp=HyperParameters()
# def build_model(hp):
#     model=tf.keras.models.Sequential()
#     model.add(tf.keras.layers.Conv2D(hp.Choice('num_filters_top_layer',values=[16,64],
#                                                default=16),(3,3),activation='relu',
#                                      input_shape=(150,150,3)))
#     model.add(tf.keras.layers.MaxPooling2D(2,2))
#     for i in range(hp.Int("num_conv_layers",1,3)):
#         model.add(tf.keras.layers.Conv2D(hp.Choice(f'num_filters_layer{i}',
#                                                    values=[16,64],
#                                                    default=16),
#                                          (3,3),activation='relu'))
#         model.add(tf.keras.layers.MaxPooling2D(2,2))
#     model.add(tf.keras.layers.Flatten())
#     model.add(tf.keras.layers.Dense(hp.Int("hidden_units",128,512,step=32),activation='relu'))
#     model.add(tf.keras.layers.Dense(1,activation='sigmoid'))
#     model.compile(optimizer=RMSprop(lr=0.001),loss='binary_crossentropy',metrics=['acc'])
#     return model
#
# tuner=Hyperband(
#     build_model,
#     objective='val_acc',
#     max_epochs=10,
#     directory='horse_human_params',
#     hyperparameters=hp,
#     project_name='my_horse_human_project'
# )
# tuner.search(train_generator,epochs=10,validation_data=validation_generator)
#
# best_hps=tuner.get_best_hyperparameters(1)[0]
# print(best_hps)
# model=tuner.hypermodel.build(best_hps)
# model.summary()
#
# # 运行模型
# import numpy as np
# from tensorflow.keras.preprocessing import image
# img=image.load_img('hu.jpg',target_size=(150,150))
# x=image.img_to_array(img)
# x=np.expand_dims(x,axis=0)
# images=np.vstack([x])
# classes=model.predict(images,batch_size=10)
# print(classes[0])
# if classes[0]>0.5:
#     print('hu.jpg is a human')
# else:
#     print('hu.jpg is a horse')
```
